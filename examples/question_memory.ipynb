{
 "metadata": {
  "name": "",
  "signature": "sha256:dfee5aa0fe4431bd0979962cb2a80ead301519221130cbd64290263d5ceadf87"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Nengo example: Simple question answering with memory\n",
      "\n",
      "This demo implements a simple form of question answering. Two features (color and shape) will be bound by circular convolution and stored in a memory population. A cue will be used to determine either one of the features by deconvolution.\n",
      "\n",
      "When you run the network, it will start by binding \u2018Red\u2019 and \u2018Circle\u2019 for 0.25s and then binding \u2018Blue\u2019 and \u2018Square\u2019 for 0.25s. Both bound semantic pointers are stored in a memory population. Then the network is asked with the cue. For example, when the cue is \u2018Circle\u2019 the network will respond with \u2018Red\u2019."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nengo\n",
      "from nengo import spa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1: Create the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Number of dimensions for the Semantic Pointers\n",
      "dimensions = 32\n",
      "\n",
      "model = spa.SPA(label=\"Simple question answering\")\n",
      "\n",
      "with model:\n",
      "    model.color_in = spa.Buffer(dimensions=dimensions)\n",
      "    model.shape_in = spa.Buffer(dimensions=dimensions)\n",
      "    model.conv = spa.Memory(dimensions=dimensions, subdimensions=4, synapse=0.4)\n",
      "    model.cue = spa.Buffer(dimensions=dimensions)\n",
      "    model.out = spa.Buffer(dimensions=dimensions)\n",
      "    \n",
      "    # Connect the buffers\n",
      "    cortical_actions = spa.Actions(\n",
      "        'conv = color_in * shape_in',\n",
      "        'out = conv * ~cue'\n",
      "    )\n",
      "    model.cortical = spa.Cortical(cortical_actions)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: Provide the input\n",
      "\n",
      "The color input will \u2018Red\u2019 and then \u2018Blue\u2019 for 0.25s each before being turned off. In the same way the shape input will be \u2018Circle\u2018 and then \u2018Square\u2019 for 0.25s each. Thus, the network will bind alternatingly \u2018Red * Circle\u2019 and \u2018Blue * Square\u2019 for 0.5s each.\n",
      "\n",
      "The cue for deconvolving bound semantic pointers will be turned off for 0.5s and then cycles through \u2018Circle\u2019, \u2018Red\u2019, \u2018Square\u2019, and \u2018Blue\u2019 within one second. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def color_input(t):\n",
      "    if t < 0.25:\n",
      "        return 'Red'\n",
      "    elif t < 0.5:\n",
      "        return 'Blue'\n",
      "    else:\n",
      "        return '0'\n",
      "\n",
      "def shape_input(t):\n",
      "    if t < 0.25:\n",
      "        return 'Circle'\n",
      "    elif t < 0.5:\n",
      "        return 'Square'\n",
      "    else:\n",
      "        return '0'\n",
      "\n",
      "def cue_input(t):\n",
      "    if t < 0.5:\n",
      "        return '0'\n",
      "    sequence = ['0', 'Circle', 'Red', '0', 'Square', 'Blue']\n",
      "    idx = int(((t - 0.5) // (1. / len(sequence))) % len(sequence))\n",
      "    return sequence[idx]\n",
      "\n",
      "with model:\n",
      "    model.inp = spa.Input(color_in=color_input, shape_in=shape_input, cue=cue_input)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3: Probe the output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    model.config[nengo.Probe].synapse = nengo.Lowpass(0.03)\n",
      "    color_in = nengo.Probe(model.color_in.state.output)\n",
      "    shape_in = nengo.Probe(model.shape_in.state.output)\n",
      "    cue = nengo.Probe(model.cue.state.output)\n",
      "    conv = nengo.Probe(model.conv.state.output)\n",
      "    out = nengo.Probe(model.out.state.output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4: Run the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(3.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 5: Plet the results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "plt.figure(figsize=(10, 10))\n",
      "vocab = model.get_default_vocab(dimensions)\n",
      "\n",
      "plt.subplot(5, 1, 1)\n",
      "plt.plot(sim.trange(), model.similarity(sim.data, color_in))\n",
      "plt.legend(model.get_output_vocab('color_in').keys, fontsize='x-small')\n",
      "plt.ylabel(\"Color\")\n",
      "\n",
      "plt.subplot(5, 1, 2)\n",
      "plt.plot(sim.trange(), model.similarity(sim.data, shape_in))\n",
      "plt.legend(model.get_output_vocab('shape_in').keys, fontsize='x-small')\n",
      "plt.ylabel(\"Shape\")\n",
      "\n",
      "plt.subplot(5, 1, 3)\n",
      "plt.plot(sim.trange(), model.similarity(sim.data, cue))\n",
      "plt.legend(model.get_output_vocab('cue').keys, fontsize='x-small')\n",
      "plt.ylabel(\"Cue\")\n",
      "\n",
      "plt.subplot(5, 1, 4)\n",
      "for pointer in ['Red * Circle', 'Blue * Square']:\n",
      "    plt.plot(sim.trange(), vocab.parse(pointer).dot(sim.data[conv].T), label=pointer)\n",
      "plt.legend(fontsize='x-small')\n",
      "plt.ylabel(\"Convolved\")\n",
      "\n",
      "plt.subplot(5, 1, 5)\n",
      "plt.plot(sim.trange(), spa.similarity(sim.data[out], vocab))\n",
      "plt.legend(model.get_output_vocab('out').keys, fontsize='x-small')\n",
      "plt.ylabel(\"Output\")\n",
      "plt.xlabel(\"t [s]\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plots of \u2018Shape\u2019, \u2018Color\u2019, and \u2018Convolved\u2019 show that first \u2018Red * Circle\u2019 and then \u2018Blue * Square\u2019 will be loaded into the \u2018Convolved\u2019 buffer so after 0.5s it represents the superposition \u2018Red * Circle + Blue * Square\u2019.\n",
      "\n",
      "The last plot shows that the output is most similar to the semantic pointer bound to the current cue. For example, when \u2018Red\u2019 and \u2018Circle\u2019 are being convolved and the cue is \u2018Circle\u2019, the output is most similar to \u2018Red\u2019. Thus, it is possible to unbind semantic pointers from the superposition stored in \u2018Convolved\u2019."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
